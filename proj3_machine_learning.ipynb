{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Car Price Prediction: Machine Leaning Models\n",
    "\n",
    "Cyrus Kolahi\n",
    "\n",
    "run proj3_data_preprocess.ipynb to preprocess and create train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data from data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/X_train_scaled.csv\")\n",
    "X_test = pd.read_csv(\"data/X_test_scaled.csv\")\n",
    "X_val = pd.read_csv(\"data/X_val_scaled.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train_scaled.csv\")\n",
    "y_test = pd.read_csv(\"data/y_test_scaled.csv\")\n",
    "y_val = pd.read_csv(\"data/y_val_scaled.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      "Test MSE: 0.00\n",
      "Val MSE: 0.00\n",
      "Test R2 Score: 1.00\n",
      "Val R2 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "LinReg = LinearRegression()\n",
    "LinReg.fit(X_train, y_train)\n",
    "lr_val_pred = LinReg.predict(X_val)\n",
    "lr_pred = LinReg.predict(X_test)\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_test, lr_pred):.2f}\")\n",
    "print(f\"Val MSE: {mean_squared_error(y_val, lr_val_pred):.2f}\")\n",
    "print(f\"Test R2 Score: {r2_score(y_test, lr_pred):.2f}\")\n",
    "print(f\"Val R2 Score: {r2_score(y_val, lr_val_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression with Kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression with linear kernel Results:\n",
      "Test MSE: 0.00\n",
      "Val MSE: 0.00\n",
      "Test R2 Score: 1.00\n",
      "Val R2 Score: 1.00\n",
      "\n",
      "Regression with rbf kernel Results:\n",
      "Test MSE: 0.00\n",
      "Val MSE: 0.00\n",
      "Test R2 Score: 1.00\n",
      "Val R2 Score: 1.00\n",
      "\n",
      "Regression with poly kernel Results:\n",
      "Test MSE: 0.00\n",
      "Val MSE: 0.00\n",
      "Test R2 Score: 1.00\n",
      "Val R2 Score: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'rbf', 'poly']\n",
    "for kernel in kernels:\n",
    "    kr = KernelRidge(kernel=kernel)\n",
    "    kr.fit(X_train, y_train)\n",
    "    test_pred = kr.predict(X_test)\n",
    "    val_pred = kr.predict(X_val)\n",
    "    print(f\"Regression with {kernel} kernel Results:\")\n",
    "    print(f\"Test MSE: {mean_squared_error(y_test, test_pred):.2f}\")\n",
    "    print(f\"Val MSE: {mean_squared_error(y_val, val_pred):.2f}\")\n",
    "    print(f\"Test R2 Score: {r2_score(y_test, test_pred):.2f}\")\n",
    "    print(f\"Val R2 Score: {r2_score(y_val, val_pred):.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Regression with different kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression (linear kernel) Results:\n",
      "Test MSE: 0.00\n",
      "Val MSE: 0.00\n",
      "Test R2 Score: 1.00\n",
      "Val R2 Score: 1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckolahi/.conda/envs/dlproject_v4/lib/python3.9/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ckolahi/.conda/envs/dlproject_v4/lib/python3.9/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression (rbf kernel) Results:\n",
      "Test MSE: 0.00\n",
      "Val MSE: 0.00\n",
      "Test R2 Score: 1.00\n",
      "Val R2 Score: 1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckolahi/.conda/envs/dlproject_v4/lib/python3.9/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression (poly kernel) Results:\n",
      "Test MSE: 0.05\n",
      "Val MSE: 0.05\n",
      "Test R2 Score: 0.95\n",
      "Val R2 Score: 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for kernel in ['linear', 'rbf', 'poly']:\n",
    "    svr = SVR(kernel=kernel)\n",
    "    svr.fit(X_train, y_train)\n",
    "    svr_pred = svr.predict(X_test)\n",
    "    svr_val_pred = svr.predict(X_val)\n",
    "    print(f\"Support Vector Regression ({kernel} kernel) Results:\")\n",
    "    print(f\"Test MSE: {mean_squared_error(y_test, svr_pred):.2f}\")\n",
    "    print(f\"Val MSE: {mean_squared_error(y_val, svr_val_pred):.2f}\")\n",
    "    print(f\"Test R2 Score: {r2_score(y_test, svr_pred):.2f}\")\n",
    "    print(f\"Val R2 Score: {r2_score(y_val, svr_val_pred):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Test MSE: 0.07\n",
      "Val MSE: 0.08\n",
      "Test R2 Score: 0.93\n",
      "Val R2 Score: 0.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(random_state=9)\n",
    "dt.fit(X_train, y_train)\n",
    "test_pred = dt.predict(X_test)\n",
    "val_pred = dt.predict(X_val)\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_test, test_pred):.2f}\")\n",
    "print(f\"Val MSE: {mean_squared_error(y_val, val_pred):.2f}\")\n",
    "print(f\"Test R2 Score: {r2_score(y_test, test_pred):.2f}\")\n",
    "print(f\"Val R2 Score: {r2_score(y_val, val_pred):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckolahi/.conda/envs/dlproject_v4/lib/python3.9/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Test MSE: 0.03\n",
      "Val MSE: 0.03\n",
      "Test R2 Score: 0.97\n",
      "Val R2 Score: 0.97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=20)\n",
    "rf.fit(X_train, y_train)\n",
    "test_pred = rf.predict(X_test)\n",
    "val_pred = rf.predict(X_val)\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_test, test_pred):.2f}\")\n",
    "print(f\"Val MSE: {mean_squared_error(y_val, val_pred):.2f}\")\n",
    "print(f\"Test R2 Score: {r2_score(y_test, test_pred):.2f}\")\n",
    "print(f\"Val R2 Score: {r2_score(y_val, val_pred):.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarPriceNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CarPriceNN, self).__init__()\n",
    "        \n",
    "        # First block with wider layers\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Second block with residual connection\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Third block decreasing dimensions\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Final prediction layers\n",
    "        self.output_layers = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        #self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Forward pass with residual connection\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        out = self.output_layers(x3)\n",
    "        return out\n",
    "\n",
    "def calculate_r2(y_true, y_pred):\n",
    "    # Ensure inputs are the right shape and scale\n",
    "    y_true = y_true.squeeze()  # Remove extra dimensions\n",
    "    y_pred = y_pred.squeeze()\n",
    "    \n",
    "    # Convert to numpy if they're torch tensors\n",
    "    if torch.is_tensor(y_true):\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "    if torch.is_tensor(y_pred):\n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate R2\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2\n",
    "\n",
    "def train_model(model, train_loader, val_loader, test_loader, epochs=50):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 10  # Early stopping patience\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            y_batch = y_batch\n",
    "            #print(y_batch.shape, X_batch.shape)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # Validation/Test\n",
    "        model.eval()\n",
    "        val_preds =[]\n",
    "        val_true=[]\n",
    "        test_preds=[]\n",
    "        test_true=[]\n",
    "        val_loss = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                #y_batch = y_batch\n",
    "                #print(y_batch.shape, X_batch.shape)\n",
    "                y_pred = model(X_batch)\n",
    "                val_loss += criterion(y_pred, y_batch).item()\n",
    "                val_preds.append(y_pred)\n",
    "                val_true.append(y_batch)\n",
    "\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                #y_batch = y_batch\n",
    "                #print(y_batch.shape, X_batch.shape)\n",
    "                y_pred = model(X_batch)\n",
    "                test_loss += criterion(y_pred, y_batch).item()\n",
    "                test_preds.append(y_pred)\n",
    "                test_true.append(y_batch)\n",
    "            \n",
    "        # Average losses\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        \n",
    "         # Concatenate all predictions and true values\n",
    "        val_true = torch.cat(val_true)\n",
    "        val_pred = torch.cat(val_preds)\n",
    "        test_true = torch.cat(test_true)\n",
    "        test_pred = torch.cat(test_preds)\n",
    "\n",
    "    \n",
    "        # Calculate R2 score\n",
    "        val_r2 = calculate_r2(val_true, val_pred)\n",
    "        test_r2 = calculate_r2(test_true, test_pred)\n",
    "    \n",
    "       \n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            break\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}: \\n Train Loss: {avg_train_loss:.4f}, \\n Val Loss: {avg_val_loss:.4f} \\n Test Loss: {avg_test_loss:.4f}')\n",
    "            print(f'Val R2: {np.mean(val_r2):.4f}, \\n'\n",
    "                  f'Test R2: {np.mean(test_r2):.4f}')\n",
    "            \n",
    "    return avg_test_loss, avg_val_loss, avg_train_loss, val_r2, test_r2\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/X_train_scaled.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train_scaled.csv\")\n",
    "X_test = pd.read_csv(\"data/X_test_scaled.csv\")\n",
    "y_test = pd.read_csv(\"data/y_test_scaled.csv\")\n",
    "X_val = pd.read_csv(\"data/X_val_scaled.csv\")\n",
    "y_val = pd.read_csv(\"data/y_val_scaled.csv\")\n",
    "\n",
    "scaler_y = pickle.load(open(\"data/scaler_y.pkl\", \"rb\"))\n",
    "scaler_X = pickle.load(open(\"data/scaler_X.pkl\", \"rb\"))\n",
    "scalers = pickle.load(open(\"data/scalers.pkl\", \"rb\"))\n",
    "\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train.values) \n",
    "y_train_tensor = torch.FloatTensor(y_train.values)\n",
    "\n",
    "train_dataset=TensorDataset(X_train_tensor,y_train_tensor)\n",
    "\n",
    "X_test_tensor = torch.FloatTensor(X_test.values) \n",
    "y_test_tensor = torch.FloatTensor(y_test.values)\n",
    "\n",
    "test_dataset=TensorDataset(X_test_tensor,y_test_tensor)\n",
    "\n",
    "X_val_tensor = torch.FloatTensor(X_val.values) \n",
    "y_val_tensor = torch.FloatTensor(y_val.values)\n",
    "\n",
    "val_dataset=TensorDataset(X_val_tensor,y_val_tensor)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = CarPriceNN(10)\n",
    "#avg_test_loss, avg_val_loss, avg_train_loss, val_r2, test_r2 = train_model(model,train_data_loader,val_data_loader,test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/X_train_scaled.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train_scaled.csv\")\n",
    "X_test = pd.read_csv(\"data/X_test_scaled.csv\")\n",
    "y_test = pd.read_csv(\"data/y_test_scaled.csv\")\n",
    "X_val = pd.read_csv(\"data/X_val_scaled.csv\")\n",
    "y_val = pd.read_csv(\"data/y_val_scaled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running trial with seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:39,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      " Train Loss: 0.2502, \n",
      " Val Loss: 0.0304 \n",
      " Test Loss: 0.0309\n",
      "Val R2: 0.9679, \n",
      "Test R2: 0.9681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:10<00:35,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \n",
      " Train Loss: 0.0727, \n",
      " Val Loss: 0.0099 \n",
      " Test Loss: 0.0099\n",
      "Val R2: 0.9895, \n",
      "Test R2: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:19<00:26,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: \n",
      " Train Loss: 0.0787, \n",
      " Val Loss: 0.0206 \n",
      " Test Loss: 0.0198\n",
      "Val R2: 0.9783, \n",
      "Test R2: 0.9795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:26<00:22,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 27\n",
      "MSE: 0.0114\n",
      "R2 Score: 0.9882\n",
      "\n",
      "Running trial with seed 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:40,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      " Train Loss: 0.3263, \n",
      " Val Loss: 0.0254 \n",
      " Test Loss: 0.0261\n",
      "Val R2: 0.9732, \n",
      "Test R2: 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:09<00:34,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \n",
      " Train Loss: 0.0747, \n",
      " Val Loss: 0.0214 \n",
      " Test Loss: 0.0209\n",
      "Val R2: 0.9774, \n",
      "Test R2: 0.9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:17<00:31,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "MSE: 0.0061\n",
      "R2 Score: 0.9937\n",
      "\n",
      "Running trial with seed 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:42,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      " Train Loss: 0.2965, \n",
      " Val Loss: 0.0158 \n",
      " Test Loss: 0.0158\n",
      "Val R2: 0.9833, \n",
      "Test R2: 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:10<00:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \n",
      " Train Loss: 0.0769, \n",
      " Val Loss: 0.0163 \n",
      " Test Loss: 0.0154\n",
      "Val R2: 0.9827, \n",
      "Test R2: 0.9841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:19<00:28,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: \n",
      " Train Loss: 0.0743, \n",
      " Val Loss: 0.0180 \n",
      " Test Loss: 0.0178\n",
      "Val R2: 0.9809, \n",
      "Test R2: 0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:29<00:20,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: \n",
      " Train Loss: 0.0729, \n",
      " Val Loss: 0.0134 \n",
      " Test Loss: 0.0130\n",
      "Val R2: 0.9859, \n",
      "Test R2: 0.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:32<00:16,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 33\n",
      "MSE: 0.0157\n",
      "R2 Score: 0.9839\n",
      "\n",
      "Running trial with seed 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:40,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      " Train Loss: 0.2569, \n",
      " Val Loss: 0.0235 \n",
      " Test Loss: 0.0239\n",
      "Val R2: 0.9752, \n",
      "Test R2: 0.9753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:10<00:40,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \n",
      " Train Loss: 0.0697, \n",
      " Val Loss: 0.0269 \n",
      " Test Loss: 0.0284\n",
      "Val R2: 0.9716, \n",
      "Test R2: 0.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:21<00:31,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: \n",
      " Train Loss: 0.0698, \n",
      " Val Loss: 0.0072 \n",
      " Test Loss: 0.0070\n",
      "Val R2: 0.9923, \n",
      "Test R2: 0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:28<00:24,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 27\n",
      "MSE: 0.0083\n",
      "R2 Score: 0.9915\n",
      "\n",
      "Running trial with seed 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:46,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      " Train Loss: 0.2265, \n",
      " Val Loss: 0.0309 \n",
      " Test Loss: 0.0304\n",
      "Val R2: 0.9674, \n",
      "Test R2: 0.9686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:10<00:36,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \n",
      " Train Loss: 0.0730, \n",
      " Val Loss: 0.0146 \n",
      " Test Loss: 0.0143\n",
      "Val R2: 0.9846, \n",
      "Test R2: 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:16<00:34,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "MSE: 0.0096\n",
      "R2 Score: 0.9901\n",
      "\n",
      "Running trial with seed 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:01<01:02,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      " Train Loss: 0.2720, \n",
      " Val Loss: 0.0306 \n",
      " Test Loss: 0.0301\n",
      "Val R2: 0.9677, \n",
      "Test R2: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:10<00:34,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \n",
      " Train Loss: 0.0716, \n",
      " Val Loss: 0.0165 \n",
      " Test Loss: 0.0165\n",
      "Val R2: 0.9825, \n",
      "Test R2: 0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:20<00:31,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: \n",
      " Train Loss: 0.0721, \n",
      " Val Loss: 0.0182 \n",
      " Test Loss: 0.0179\n",
      "Val R2: 0.9808, \n",
      "Test R2: 0.9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:29<00:16,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: \n",
      " Train Loss: 0.0751, \n",
      " Val Loss: 0.0219 \n",
      " Test Loss: 0.0213\n",
      "Val R2: 0.9769, \n",
      "Test R2: 0.9781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:32<00:16,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 33\n",
      "MSE: 0.0118\n",
      "R2 Score: 0.9879\n",
      "\n",
      "Running trial with seed 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      " Train Loss: 0.2575, \n",
      " Val Loss: 0.0296 \n",
      " Test Loss: 0.0307\n",
      "Val R2: 0.9687, \n",
      "Test R2: 0.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:10<00:40,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \n",
      " Train Loss: 0.0743, \n",
      " Val Loss: 0.0229 \n",
      " Test Loss: 0.0233\n",
      "Val R2: 0.9759, \n",
      "Test R2: 0.9760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:20<00:29,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: \n",
      " Train Loss: 0.0757, \n",
      " Val Loss: 0.0115 \n",
      " Test Loss: 0.0113\n",
      "Val R2: 0.9879, \n",
      "Test R2: 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:24<00:26,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 24\n",
      "MSE: 0.0107\n",
      "R2 Score: 0.9889\n",
      "\n",
      "Running trial with seed 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:01<00:50,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      " Train Loss: 0.2519, \n",
      " Val Loss: 0.0404 \n",
      " Test Loss: 0.0422\n",
      "Val R2: 0.9574, \n",
      "Test R2: 0.9565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:10<00:35,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \n",
      " Train Loss: 0.0769, \n",
      " Val Loss: 0.0148 \n",
      " Test Loss: 0.0145\n",
      "Val R2: 0.9844, \n",
      "Test R2: 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:18<00:32,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "MSE: 0.0261\n",
      "R2 Score: 0.9731\n",
      "\n",
      "Running trial with seed 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      " Train Loss: 0.3051, \n",
      " Val Loss: 0.0260 \n",
      " Test Loss: 0.0262\n",
      "Val R2: 0.9726, \n",
      "Test R2: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:10<00:39,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: \n",
      " Train Loss: 0.0809, \n",
      " Val Loss: 0.0169 \n",
      " Test Loss: 0.0156\n",
      "Val R2: 0.9822, \n",
      "Test R2: 0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:20<00:26,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: \n",
      " Train Loss: 0.0627, \n",
      " Val Loss: 0.0099 \n",
      " Test Loss: 0.0112\n",
      "Val R2: 0.9896, \n",
      "Test R2: 0.9885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:28<00:22,  1.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[192], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning trial with seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m     avg_test_loss, avg_val_loss, avg_train_loss, val_r2, test_r2 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: seed,\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval loss\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_val_loss,   \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest r2\u001b[39m\u001b[38;5;124m'\u001b[39m: test_r2\n\u001b[1;32m     66\u001b[0m     })\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_test_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[192], line 44\u001b[0m, in \u001b[0;36mrun_trial\u001b[0;34m(seed, X_train, y_train, X_val, y_val, X_test, y_test)\u001b[0m\n\u001b[1;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m CarPriceNN(input_dim)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m avg_test_loss, avg_val_loss, avg_train_loss, val_r2, test_r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg_test_loss, avg_val_loss, avg_train_loss, val_r2, test_r2\n",
      "Cell \u001b[0;32mIn[189], line 88\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, test_loader, epochs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m#print(y_batch.shape, X_batch.shape)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 88\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y_batch)\n\u001b[1;32m     90\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/dlproject_v4/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dlproject_v4/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[189], line 47\u001b[0m, in \u001b[0;36mCarPriceNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Forward pass with residual connection\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x1)\n\u001b[1;32m     49\u001b[0m     x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x2)\n",
      "File \u001b[0;32m~/.conda/envs/dlproject_v4/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dlproject_v4/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/dlproject_v4/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/dlproject_v4/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dlproject_v4/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/dlproject_v4/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dlproject_v4/lib/python3.9/site-packages/torch/nn/functional.py:2812\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2810\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def run_trial(seed, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"Run a single trial with given random seed\"\"\"\n",
    "    # Set the seed\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Create datasets\n",
    "    X_train_tensor = torch.FloatTensor(X_train.values) \n",
    "    y_train_tensor = torch.FloatTensor(y_train.values)\n",
    "\n",
    "    train_dataset=TensorDataset(X_train_tensor,y_train_tensor)\n",
    "\n",
    "    X_test_tensor = torch.FloatTensor(X_test.values) \n",
    "    y_test_tensor = torch.FloatTensor(y_test.values)\n",
    "\n",
    "    test_dataset=TensorDataset(X_test_tensor,y_test_tensor)\n",
    "\n",
    "    X_val_tensor = torch.FloatTensor(X_val.values) \n",
    "    y_val_tensor = torch.FloatTensor(y_val.values)\n",
    "\n",
    "    val_dataset=TensorDataset(X_val_tensor,y_val_tensor)\n",
    "\n",
    "\n",
    "    batch_size = 32\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Initialize model\n",
    "    input_dim = X_train.shape[1]\n",
    "    model = CarPriceNN(input_dim)\n",
    "    \n",
    "    # Train model\n",
    "    avg_test_loss, avg_val_loss, avg_train_loss, val_r2, test_r2 = train_model(model, train_data_loader, val_data_loader, test_data_loader)\n",
    "\n",
    "    return avg_test_loss, avg_val_loss, avg_train_loss, val_r2, test_r2\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Run multiple trials with different seeds\n",
    "seeds = [42, 43, 44, 45, 46, 100, 200, 400, 333, 73] \n",
    "results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\nRunning trial with seed {seed}\")\n",
    "    avg_test_loss, avg_val_loss, avg_train_loss, val_r2, test_r2 = run_trial(seed, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    results.append({\n",
    "        'seed': seed,\n",
    "        'val loss': avg_val_loss,   \n",
    "        'test loss': avg_test_loss,\n",
    "        'train loss': avg_train_loss,\n",
    "        'val r2': val_r2,\n",
    "        'test r2': test_r2\n",
    "    })\n",
    "    print(f\"MSE: {avg_test_loss:.4f}\")\n",
    "    print(f\"R2 Score: {test_r2:.4f}\")\n",
    "\n",
    "# Calculate average performance\n",
    "avg_mse_test = np.mean([r['test loss'] for r in results])\n",
    "avg_r2_test = np.mean([r['test r2'] for r in results])\n",
    "avg_mse_val = np.mean([r['val loss'] for r in results])\n",
    "avg_r2_val = np.mean([r['val r2'] for r in results])\n",
    "\n",
    "print(\"\\nOverall Results:\")\n",
    "print(f\"Average Test Loss: {avg_mse_test:.4f}\")\n",
    "print(f\"Average Test r2 Score: {avg_r2_test:.4f}\")\n",
    "\n",
    "# Print individual results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
